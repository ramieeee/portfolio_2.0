[
  {
    "id": 6,
    "title": "LSTM-MLP-based Korean Hate Speech Detection Using Pixel Coordinates of Image-Transformed Text and Vector Features",
    "subtitle": "이미지화된 텍스트의 픽셀 위치 좌표와 벡터 특징을 활용한 LSTM-MLP 기반 한글 혐오 표현 탐지",
    "category": "Master's Thesis",
    "thumbnail": [
      "projectImages/thesis/thesis1.png",
      "projectImages/thesis/thesis2.png",
      "projectImages/thesis/thesis3.png"
    ],
    "organization": "Soongsil University, Seoul",
    "time": {
      "from": {
        "year": 2024,
        "month": 3,
        "day": 7
      },
      "until": {
        "now": false,
        "year": 2024,
        "month": 12,
        "day": 30
      }
    },
    "description": "I proposed a model that extracts features using two differenct feature extractors, concatenates the vectors, and then understands the sentences through a dense layer.\nI used two types of feature data: one is the feature vectorized through embedding in the traditional way and interpreted through an LSTM extractor, and the other is the feature extracted through MLP by utilizing the index representing the pixel position where the text is located as coordinates by converting the text into an image.",
    "descriptionPartial": [
      {
        "image": "projectImages/thesis/thesis2.png",
        "text": "I proposed a model that extracts features using two differenct feature extractors, concatenates the vectors, and then understands the sentences through a dense layer.\nI used two types of feature data: one is the feature vectorized through embedding in the traditional way and interpreted through an LSTM extractor, and the other is the feature extracted through MLP by utilizing the index representing the pixel position where the text is located as coordinates by converting the text into an image."
      },
      {
        "image": "projectImages/thesis/thesis3.png",
        "text": "대학원에서 진행한 논문 연구입니다. 텍스트를 두가지 특징으로 나누어 각각의 특징추출기를 통해 특징을 추출하고 벡터들을 concat하고 다시 dense layer를 통해 문장을 파악하는 구조의 알고리즘을 제안하였습니다.\n텍스트를 기존과 같은 방식의 임베딩을 통해 벡터화된 특징을 LSTM 추출기를 통하여 해석하는 방법과, 텍스트를 이미지화 하여 글자가 위치한 픽셀 위치를 나타내는 인덱스를 좌표로 활용하여 MLP를 통해 추출한 특징 데이터 두가지를 활용하였습니다. 기존 LSTM은 두개의 테스트 데이터셋에 대한 실험 결과 각각 86.85%, 그리고 82.51% F1-score를 나타냈고, 제안 모델인 LSTM-MLP는 각각 88.13%, 85.98%의 F1-score를 보였습니다."
      }
    ],
    "contribution": null,
    "skills": ["NLP", "Deep Learning", "FastText", "Python"],
    "url": "https://github.com/ramieeee/thesis_masters"
  },
  {
    "id": 5,
    "title": "RAG LLM Automation",
    "subtitle": "",
    "category": "AI",
    "thumbnail": ["projectImages/ezfarm/ezfarm1.png"],
    "organization": "Ezfarm Inc.",
    "time": {
      "from": {
        "year": 2024,
        "month": 10,
        "day": 7
      },
      "until": {
        "now": false,
        "year": 2025,
        "month": 2,
        "day": 25
      }
    },
    "description": "Built a LLM automation using LangChain.Developed a RAG model that answers based on real existing data with natural language processing input, and also built an automated LLM model that can retrieve data from the database.",
    "descriptionPartial": [
      {
        "image": null,
        "text": "Built a LLM automation using LangChain. Developed a RAG model that answers based on real existing data with natural language processing input, and also built an automated LLM model that can retrieve data from the database."
      },
      {
        "image": null,
        "text": "LangChain was quite new to the world, so I learned it from scratch. I even built a memory system in the RAG automation pipeline manually, by feeding several conversation threads into the model. "
      },
      {
        "image": null,
        "text": "I not only built the RAG model, but also created an automated LLM model that can retrieve data from the database. This involved setting up the necessary infrastructure and ensuring seamless integration with existing systems. In these days it is called Text-to-SQL model."
      },
      {
        "image": null,
        "text": "It had a little problem in the model's accuracy, showing the phenomenon so called hallucination. General prompting not have seemed to be the solution, so I took a chance to implement a Named Entity Recognition (NER) method to improve the accuracy of the LLM model. By recognizing and extracting specific entities from the input text, the NER data helped to provide more structured and relevant information to the LLM, thereby reducing hallucination by 50-60% and improving overall performance."
      }
    ],
    "skills": [
      "LangChain",
      "Typescript",
      "Python",
      "FastAPI",
      "Docker",
      "Apache Atlas"
    ],
    "contribution": [
      "Launched a RAG LLM prototype",
      "Launched a Text-to-SQL LLM prototype"
    ],
    "url": ""
  },
  {
    "id": 4,
    "title": "Pubty",
    "subtitle": "",
    "category": "MobileApp",
    "thumbnail": [
      "projectImages/pubty/pubty1.svg",
      "projectImages/pubty/pubty2.svg",
      "projectImages/pubty/pubty3.svg"
    ],
    "organization": "Personal",
    "time": {
      "from": {
        "year": 2024,
        "month": 2,
        "day": 1
      },
      "until": {
        "now": false,
        "year": 2024,
        "month": 12,
        "day": 30
      }
    },
    "description": "It is a pub searching mobile application, which allows you to customize filters to find pubs that suit your preferences. You can search for pubs based on various criteria such as location, ambiance, drink menu, and more. The app provides detailed information about each pub, including reviews and ratings from other users.",
    "descriptionPartial": [
      {
        "image": "",
        "text": "It is a pub searching mobile application, which allows you to customize filters to find pubs that suit your preferences. You can search for pubs based on various criteria such as location, ambiance, drink menu, and more. The app provides detailed information about each pub, including reviews and ratings from other users."
      },
      {
        "image": "",
        "text": "I am building this application just because I want to, and I love pubs, especially drinking with colleagues and friends."
      }
    ],
    "skills": ["React Native", "Typescript", "Firebase", "GCP"],
    "contribution": [
      "1인 개발",
      "기획, 개발 등 모든 부분을 혼자 담당하여 프로젝트 진행"
    ],
    "url": ""
  },
  {
    "id": 3,
    "title": "OpenFrame Refactor",
    "subtitle": "",
    "category": "Web",
    "thumbnail": [
      "projectImages/openFrameRefactor/openFrameRefactor1.png",
      "projectImages/openFrameRefactor/openFrameRefactor2.png"
    ],
    "organization": "TmaxSoft",
    "time": {
      "from": {
        "year": 2024,
        "month": 6,
        "day": 1
      },
      "until": {
        "now": false,
        "year": 2024,
        "month": 12,
        "day": 1
      }
    },
    "description": "It was a project aimed at SaaS-ifying the solution while working at TmaxSoft. I was responsible for UI development in this project, specifically for the frontend development of the Portal and Console.",
    "descriptionPartial": [
      {
        "image": "",
        "text": "It was a project aimed at SaaS-ifying the solution while working at TmaxSoft. I was responsible for UI development in this project, specifically for the frontend development of the Portal and Console."
      }
    ],
    "skills": ["React", "Typescript"],
    "contribution": [
      "SaaS Portal designing and planning with Figma",
      "UI development and component development for the Portal and Console pages"
    ],
    "url": ""
  },
  {
    "id": 2,
    "title": "DatasetManager",
    "subtitle": "",
    "category": "Web",
    "thumbnail": [],
    "organization": "TmaxSoft",
    "time": {
      "from": {
        "year": 2022,
        "month": 2,
        "day": 1
      },
      "until": {
        "now": false,
        "year": 2024,
        "month": 12,
        "day": 1
      }
    },
    "description": "I developed the frontend of a product that helps manage datasets in an open environment corresponding to the Mainframe's dataset.",
    "descriptionPartial": [
      {
        "image": "",
        "text": "I developed the frontend of a product that helps manage datasets in an open environment corresponding to the Mainframe's dataset."
      }
    ],
    "skills": ["React", "Typescript", "Nextjs", "React-query", "Docker"],
    "contribution": [
      "Mainly focused on building reusable components and UI elements, which reduced development time for new pages by 30%",
      "Pioneered to adopt Next.js and React-query, spreading know-how to the team"
    ],
    "url": ""
  }
]
